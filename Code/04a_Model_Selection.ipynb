{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring warnings about memory from running gridsearch with n_jobs=-1\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_df = pd.read_csv('../Data/fitness_clean.csv', index_col=0)\n",
    "bodyweight_df = pd.read_csv('../Data/bodyweight_clean.csv', index_col=0)\n",
    "\n",
    "all_posts = pd.concat([fitness_df, bodyweight_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyweightfitness    0.512388\n",
       "Fitness              0.487612\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null model accuracy\n",
    "all_posts['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_posts['selftext']\n",
    "y = all_posts['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(stop_words='english'), StandardScaler(with_mean=False), LogisticRegression(max_iter=10_000))\n",
    "params = {\n",
    "    'tfidfvectorizer__max_features': [800, 1000],\n",
    "    'tfidfvectorizer__ngram_range': [(1,1), (1,2)],\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1]\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1],\n",
       "                         'tfidfvectorizer__max_features': [800, 1000],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156365045533811"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846556233653008"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.001,\n",
       " 'tfidfvectorizer__max_features': 800,\n",
       " 'tfidfvectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(stop_words='english'), StandardScaler(with_mean=False), KNeighborsClassifier())\n",
    "params = {\n",
    "    'tfidfvectorizer__max_features': [800, 1000],\n",
    "    'tfidfvectorizer__ngram_range': [(1,1), (1,2)],\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 15]\n",
    "}\n",
    "grid = GridSearchCV(pipe, params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': [3, 5, 15],\n",
       "                         'tfidfvectorizer__max_features': [800, 1000],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5863204805270297"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553618134263295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Multiple Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'clf': [MultinomialNB()]\n",
    "    }, {\n",
    "        'clf': [DecisionTreeClassifier()]\n",
    "    }, {\n",
    "        'clf': [RandomForestClassifier()]\n",
    "    }, {\n",
    "        'clf': [SVC()]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_features=1000,\n",
       "                                                        stop_words='english')),\n",
       "                                       ('scaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf': [MultinomialNB()]},\n",
       "                         {'clf': [DecisionTreeClassifier()]},\n",
       "                         {'clf': [RandomForestClassifier()]},\n",
       "                         {'clf': [SVC()]}])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975779887618679"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916303400174368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.802243</td>\n",
       "      <td>0.040275</td>\n",
       "      <td>0.219029</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>{'clf': MultinomialNB()}</td>\n",
       "      <td>0.753511</td>\n",
       "      <td>0.770460</td>\n",
       "      <td>0.763081</td>\n",
       "      <td>0.747578</td>\n",
       "      <td>0.777132</td>\n",
       "      <td>0.762352</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.494947</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>0.200596</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>{'clf': DecisionTreeClassifier()}</td>\n",
       "      <td>0.686683</td>\n",
       "      <td>0.709927</td>\n",
       "      <td>0.717539</td>\n",
       "      <td>0.694283</td>\n",
       "      <td>0.715116</td>\n",
       "      <td>0.704710</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.596085</td>\n",
       "      <td>0.064968</td>\n",
       "      <td>0.208224</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'clf': RandomForestClassifier()}</td>\n",
       "      <td>0.784504</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.772287</td>\n",
       "      <td>0.783915</td>\n",
       "      <td>0.784052</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.062987</td>\n",
       "      <td>0.128496</td>\n",
       "      <td>2.934934</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>{'clf': SVC()}</td>\n",
       "      <td>0.764649</td>\n",
       "      <td>0.776755</td>\n",
       "      <td>0.775678</td>\n",
       "      <td>0.745155</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.768261</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.802243      0.040275         0.219029        0.004551   \n",
       "1       2.494947      0.028726         0.200596        0.006785   \n",
       "2       7.596085      0.064968         0.208224        0.015616   \n",
       "3      15.062987      0.128496         2.934934        0.034718   \n",
       "\n",
       "                  param_clf                             params  \\\n",
       "0           MultinomialNB()           {'clf': MultinomialNB()}   \n",
       "1  DecisionTreeClassifier()  {'clf': DecisionTreeClassifier()}   \n",
       "2  RandomForestClassifier()  {'clf': RandomForestClassifier()}   \n",
       "3                     SVC()                     {'clf': SVC()}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.753511           0.770460           0.763081           0.747578   \n",
       "1           0.686683           0.709927           0.717539           0.694283   \n",
       "2           0.784504           0.796610           0.782946           0.772287   \n",
       "3           0.764649           0.776755           0.775678           0.745155   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.777132         0.762352        0.010781                3  \n",
       "1           0.715116         0.704710        0.012114                4  \n",
       "2           0.783915         0.784052        0.007715                1  \n",
       "3           0.779070         0.768261        0.012577                2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Since the task is to predict which of two subreddits a given post belongs to with no preference for either, I will use basic accuracy as my primary metric.  In addition, the classes are well balanced which also lends itself to using accuracy as the main metric.  Based on the accuracy scores, I will focus on LogisticRegression, MultinomialNB, RandomForestClassifier, and SVC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
